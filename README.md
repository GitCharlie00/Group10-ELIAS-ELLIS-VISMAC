# üë• Group10-ELIAS-ELLIS-VISMAC
### üìç Brunico (BZ) :calendar: 27-31/01/2025

## üìã Project Track
This project aims to develop a fine-tuning technique to mitigate gender and ethnicity biases in VLMs. The evaluation will focus on biases related to a predefined set of professions (e.g., doctor, nurse, etc‚Ä¶) using a provided evaluation dataset. Given that fine-tuning can influence the model‚Äôs generalization capabilities, students will also assess the zero-shot performance of the fine-tuned model on two domain-specific datasets. This dual evaluation will help identify trade-offs introduced by the debiasing process

### ‚úîÔ∏è Implemented Method
Due to the scarcity of datasets for mitigating race and gender biases, we decided to generate the first captions (prompts) and then corresponding images.
The prompts are all generated by specifying a race, a gender, and a corresponding job. 

The **gender** options are:
- **Male**
- **Female**
  
The option **races** are:
- **Asian**
- **Indian**
- **Black**
- **White**
  
**Job** categories are:
- **Driver**
- **Cleaner**
- **CEO**
- **Nurse**
- **Doctor**
- **Sheriff**
- **Chef**
- **Secretary**
  
Example of **captions** are:
- *A young female driver of indian descent who specializes in long-haul trucking known for his efficiency and excellent safety record*
- *A seasoned indian woman truck driver specializing in cross-country freight transport known for her expert navigation skills* 

#### 



[Synthetic Demographic Dataset](https://www.kaggle.com/datasets/anthonytherrien/synthetic-population-demographics-dataset?resource=download)

[Dataset containing face images with gender and race but NOT professions](https://huggingface.co/datasets/HuggingFaceM4/FairFace)

[A model to generate images](https://huggingface.co/XLabs-AI/flux-RealismLora?)
